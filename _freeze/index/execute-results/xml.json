{
  "hash": "a3979414f72b5f8523b5420b50b84338",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Detecting misfitting items in Rasch models\nauthor:\n  - name: 'Magnus Johansson'\n    affiliation: 'RISE Research Institutes of Sweden'\n    affiliation-url: 'https://ri.se/shic'\n    orcid: '0000-0003-1669-592X'\nkeywords:\n  - Rasch\n  - Psychometrics\n  - Item fit\n  - Simulation\nabstract: |\n  Psychometrics in general have long relied on rule-of-thumb cutoff values for various goodness of fit metrics. With more powerful personal computers it is both feasible and desirable to use simulation/bootstrap methods to determine appropriate cutoff values. This paper illustrates and evaluates the use of an R package for Rasch psychometrics that has implemented functions to simplify the process of identifying misfitting items using simulation based cutoff values. Through a series of simulation studies a comparison is made between information weighted conditional item fit and item-restscore using Goodman and Kruskal’s gamma.\nkey-points:\n  - Sample size affects the detection rate and false positives rate\n  - Number of misfitting items increases false positive rate\ndate: last-modified\nbibliography: references.bib\nnumber-sections: true\nrepo-url: 'https://github.com/pgmj/rasch_itemfit'\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\n\n## Introduction\n\nThis paper presents a series of simulations conducted to evaluate methods to detect of item misfit in Rasch models. First, conditional item infit and outfit will be under scrutiny. Second, item infit will be compared to item-restscore [@kreiner_note_2011;@mueller_iarm_2022]. Third, a bootstrap method for item-restscore will be presented and tested.\n\nMüller [-@muller_item_2020] showed how the range of conditional item infit varies with sample size and the expected average item infit range is fairly well captured by Smith's rule-of-thumb formula (1±2/√n). However, the average range does not apply for all items, since item location also affects model expected item fit which means some items may have plausible item fit values outside Smith's average value range.\n\nIt is proposed that by using parametric bootstrapping one can establish item fit cutoff values that are sample and item specific. The R package `easyRasch` [@easyrasch] includes a function to determine item infit and outfit cutoff values, which will be tested in the simulations in this paper.\n\nIt is important to note that the conditional item fit described by Müller [-@muller_item_2020] and implemented in the `iarm` R package [@mueller_iarm_2022] is different from the unconditional item fit implemented in software such as Winsteps and RUMM2030, as well as all R packages except `iarm`. Unconditional item fit can result in unreliable item fit in sample sizes as small as 250 with increasing likelihood of problems as sample size increases. Readers are strongly recommended to read Müller's paper to fully understand the problems with unconditional item fit.\n\n## Methods {#sec-methods}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(iarm)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: eRm\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: ggplot2\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(eRm)\nlibrary(ggdist)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(easyRasch)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: formattable\nLoading required package: kableExtra\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nLoading required package: mirt\nLoading required package: stats4\nLoading required package: lattice\n\nAttaching package: 'mirt'\n\nThe following objects are masked from 'package:eRm':\n\n    itemfit, personfit\n\nLoading required package: psych\n\nAttaching package: 'psych'\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\nThe following object is masked from 'package:eRm':\n\n    sim.rasch\n\nLoading required package: psychotree\nLoading required package: partykit\nLoading required package: grid\nLoading required package: libcoin\nLoading required package: mvtnorm\nLoading required package: psychotools\nLoading required package: matrixStats\n\nAttaching package: 'matrixStats'\n\nThe following object is masked from 'package:dplyr':\n\n    count\n\nLoading required package: reshape\n\nAttaching package: 'reshape'\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\nThe following object is masked from 'package:dplyr':\n\n    rename\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, smiths\n\nLoading required package: patchwork\n\nAttaching package: 'patchwork'\n\nThe following object is masked from 'package:formattable':\n\n    area\n\nLoading required package: ggrepel\nLoading required package: glue\nLoading required package: catR\nLoading required package: hexbin\nLoading required package: janitor\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nLoading required package: foreach\n\nAttaching package: 'foreach'\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\nLoading required package: furrr\nLoading required package: future\nLoading required package: doParallel\nLoading required package: iterators\nLoading required package: parallel\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(arrow)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nSome features are not enabled in this build of Arrow. Run `arrow_info()` for more information.\nThe repository you retrieved Arrow from did not include all of Arrow's features.\nYou can install a fully-featured version by running:\n`install.packages('arrow', repos = 'https://apache.r-universe.dev')`.\n\nAttaching package: 'arrow'\n\nThe following object is masked from 'package:lubridate':\n\n    duration\n\nThe following object is masked from 'package:utils':\n\n    timestamp\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n### some commands exist in multiple packages, here we define preferred ones that are frequently used\nselect <- dplyr::select\ncount <- dplyr::count\nrename <- dplyr::rename\n```\n:::\n\n\n\n\n\n\n\nThe simulation of response data used three steps: first, a vector of theta values (person scores on the latent variable) were generated using `rnorm(mean = 0, sd = 1.5)`. Second, a set of item locations ranging from -2 to 2 logits were generated for dichotomous items, using `runif(n = 20, min = -2, max = 2)`. Third, the theta values were used to simulate item responses for participants, using `sim.xdim()` from the `eRm` package [@mair_extended_2007], which allows simulation of multidimensional response data. Multiple datasets were generated using the same item and person parameters, varying the targeting and number of the misfitting item(s). More details are described under the separate studies below.\n\nThe parametric bootstrapping procedure was implemented using random samples from the 10 000 simulated responses. The sample size variations tested are described under each study. \n\n1. Estimation of item locations based on simulated item responses using conditional maximum likelihood [CML, @mair_extended_2007].\n2. Estimation of sample theta values using weighted maximum likelihood [@warm_weighted_1989]\n3. Simulation of new response data, fitting the Rasch model, using the estimated item locations and theta values.\n4. Estimation of the dichotomous Rasch model for the new response data using CML.\n5. Based on step 4, calculation of conditional item fit [@muller_item_2020;@mueller_iarm_2022] and/or item-restscore metrics [@kreiner_note_2011;@mueller_iarm_2022].\n\nSteps three and four were iterated over, using resampling with replacement from the estimated theta values as a basis for simulating the response data in step three.\n\nSummary statistics were created with focus on correctly detecting misfit and whether false positives were identified.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# read pre-generated item locations for reproducibility\nitems1 <- read_csv(\"data/rm_items40.csv\") %>%\n  slice(1:20) %>% \n  pull(location)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 40 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): item, location\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# a matrix to specify which dimension each item loads on\nwmat0 <- matrix(nrow = 20,\n               ncol = 2)\n# set all items to load on dimension one\nwmat0[1:20,1] <- 1\nwmat0[1:20,2] <- 0\n# item 9, with good targeting in this item set (closest to sample theta mean of 0), is chosen to belong to a second dimension\nwmat0[9,1] <- 0\nwmat0[9,2] <- 1\n\n# a matrix to specify which dimension each item loads on\nwmat1 <- matrix(nrow = 20,\n               ncol = 2)\nwmat1[1:20,1] <- 1\nwmat1[1:20,2] <- 0\nwmat1[18,1] <- 0\nwmat1[18,2] <- 1\n\n# a matrix to specify which dimension each item loads on\nwmat2 <- matrix(nrow = 20,\n               ncol = 2)\nwmat2[1:20,1] <- 1\nwmat2[1:20,2] <- 0\nwmat2[13,1] <- 0\nwmat2[13,2] <- 1\n\n# generate dichotomous data\nsimdata0 <- eRm::sim.xdim(10000, items1, cutpoint = \"randomized\", Sigma = sigma, weightmat = wmat0)\nsimdata1 <- eRm::sim.xdim(10000, items1, cutpoint = \"randomized\", Sigma = sigma, weightmat = wmat1)\nsimdata2 <- eRm::sim.xdim(10000, items1, cutpoint = \"randomized\", Sigma = sigma, weightmat = wmat2)\n\nsimdata <- list(data0 = simdata0,\n                data1 = simdata1,\n                data2 = simdata2)\n#saveRDS(simdata,\"simdata10000.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsimdata <- readRDS(\"data/simdata10000.rds\")\ndemodata <- simdata[[1]] %>% \n  as.data.frame() %>% \n  slice(1:400) %>% \n  select(V1,V11,V3,V12)\n```\n:::\n\n\n\n\n\n\n## Study 1\n\nConditional mean square (MSQ) infit and outfit, henceforth referred to only as infit or outfit. **Refer to Müller (and vignette ref) for technical description...**\n\nMain lines of inquiry:\n\n1. How does the number of iterations used in RIgetfit() impact the indicated cutoff values?\n2. How useful are the cutoff values in detecting misfitting items (and false positives), when using the optimal number of iterations?\n3. Müller [-@muller_item_2020] hints at outfit being less useful than infit. We will investigate this by comparing them.\n\n20 dichotomous items are used, with one item misfitting. Item locations are the same throughout. The location of the misfitting item relative the to the sample theta mean was selected to be approximately 0, -1, and -2 logits. Three separate datasets were generated with these variations, each with 10 000 simulated respondents. One dataset with all three misfitting items was also generated, using the same sample size.\n\nThe function `RIgetfit()` from the `easyRasch` R package is tested here. It's source code can be accessed on GitHub. The function offers the user a choice of the number of bootstrap iterations to use to calculate the cutoff values for infit and outfit.\n\nThen the `RIitemfit()` function is used to summarize the bootstrap results and also calculates the infit and outfit for each item in the observed data and highlights items with infit/outfit values outside of the cutoff values. `RIitemfit()` has a default setting to slightly truncate the distribution of values using `stats::quantile()` at 0.001 and 0.999 to reduce extreme values. An example is demonstrated in @tbl-itemfit1, using a subset of the items used in the simulations. @fig-itemfit1 provides a visualization of the distribution of bootstrapped infit and outfit values, together with the observed infit/outfit indicated with an orange diamond shape. Note the variation between items in plausible values of infit and outfit based on the bootstrap, and that Smith's rule-of-thumb regarding infit (1±2/√n) would be 0.9-1.1 for a sample size of 400.\n\nThis study was rather computationally demanding since each simulation run entailed 100-400 underlying simulations. The sample sizes used were 150, 250, 500, and 1000. The number of iterations to determine cutoff values were 100, 200, and 400. Sample size and iteration conditions were fully crossed with each other and the three different targeting variations of the one misfitting item, resulting in 4*3*3 = 36 conditions. Each combination used 200 simulation runs. The simulations took about 12 hours to run on a Macbook Pro Max M1 using 9 CPU cores.\n\n\n\n\n\n\n::: {#tbl-itemfit1 .cell}\n\n```{.r .cell-code .hidden}\nsimfit <- RIgetfit(demodata, iterations = 400, cpu = 8)\nRIitemfit(demodata, simfit, output = \"quarto\")\n```\n\n::: {.cell-output-display}\n\n\n|Item | InfitMSQ|Infit thresholds | OutfitMSQ|Outfit thresholds |Infit diff |Outfit diff | Location|\n|:----|--------:|:----------------|---------:|:-----------------|:----------|:-----------|--------:|\n|V1   |    1.017|[0.864, 1.137]   |     1.061|[0.624, 1.541]    |no misfit  |no misfit   |    -1.37|\n|V11  |    1.000|[0.826, 1.166]   |     1.032|[0.687, 1.265]    |no misfit  |no misfit   |    -0.66|\n|V3   |    1.022|[0.899, 1.116]   |     1.050|[0.632, 1.474]    |no misfit  |no misfit   |     0.46|\n|V12  |    0.966|[0.827, 1.185]   |     0.793|[0.777, 1.27]     |no misfit  |no misfit   |     1.58|\n\n\n:::\n:::\n\n::: {#cell-fig-itemfit1 .cell}\n\n```{.r .cell-code .hidden}\nRIgetfitPlot(simfit, demodata)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-jats/fig-itemfit1-1.png){#fig-itemfit1}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# define function to run simulations for item infit/outfit cutoff values\nitemfitboot <- function(dat, iterations, samplesize) {\n  \n  fit <- list()\n  fit <- foreach(i = 1:iterations) %do% {\n    data <- dat[sample(1:nrow(dat), samplesize), ] %>% \n      as.data.frame()\n    \n    # check data for responses in all cells\n    n_resp <-\n      data %>%\n      as.matrix() %>%\n      colSums2() %>%\n      t() %>%\n      as.vector()\n    \n    if (min(n_resp, na.rm = TRUE) < 11) {\n      data <- dat[sample(1:nrow(dat), samplesize), ] %>% \n        as.data.frame()\n    } \n    \n    # get simulation based cutoff values\n    sfit100 <- RIgetfit(data,100,9)\n    sfit200 <- RIgetfit(data,200,9)\n    sfit400 <- RIgetfit(data,400,9)\n\n    # apply cutoffs and store results\n    rfit100 <- RIitemfit(data,sfit100, output = \"dataframe\") %>% \n      select(infit_msq,outfit_msq,infit_diff,outfit_diff) %>% \n      add_column(item = 1:ncol(data),\n                 sims = 100,\n                 iteration = i,\n                 samplesize = samplesize)\n    \n    rfit200 <- RIitemfit(data,sfit200, output = \"dataframe\") %>% \n      select(infit_msq,outfit_msq,infit_diff,outfit_diff) %>% \n      add_column(item = 1:ncol(data),\n                 sims = 200,\n                 iteration = i,\n                 samplesize = samplesize)\n    \n    rfit400 <- RIitemfit(data,sfit400, output = \"dataframe\") %>% \n      select(infit_msq,outfit_msq,infit_diff,outfit_diff) %>% \n      add_column(item = 1:ncol(data),\n                 sims = 400,\n                 iteration = i,\n                 samplesize = samplesize)\n    \n    # combine output \n    fit <- rbind(rfit100,rfit200,rfit400)\n  }\n  return(fit)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsamplesizes <- c(150,250,500,1000)\n\nifb0 <- list()\nifb1 <- list()\nifb2 <- list()\n\n#library(tictoc)\n#tic()\nifb0 <- map(samplesizes, ~ itemfitboot(simdata[[1]], iterations = 200, samplesize = .x))\n#toc() # 14257.358 sec elapsed\n\nifb1 <- map(samplesizes, ~ itemfitboot(simdata[[2]], iterations = 200, samplesize = .x))\nifb2 <- map(samplesizes, ~ itemfitboot(simdata[[3]], iterations = 200, samplesize = .x))\n\n# saveRDS(ifb0, \"data/ifb0_200.rds\")\n# saveRDS(ifb2, \"data/ifb2_200.rds\")\n# saveRDS(ifb1, \"data/ifb1_200.rds\")\n\nifb0_df <- map_dfr(1:4, ~ do.call(\"rbind\", ifb0[[.x]])) %>% \n  add_column(targeting = 0)\n\nifb1_df <- map_dfr(1:4, ~ do.call(\"rbind\", ifb1[[.x]])) %>% \n  add_column(targeting = 1)\n\nifb2_df <- map_dfr(1:4, ~ do.call(\"rbind\", ifb2[[.x]])) %>% \n  add_column(targeting = 2)\n\nifb <- rbind(ifb0_df,ifb1_df,ifb2_df)\n\nwrite_parquet(ifb,\"data/ifb.parquet\")\n```\n:::\n\n\n\n\n\n\n\n### Results\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nifb <- read_parquet(\"data/ifb.parquet\")\n```\n:::\n\n\n\n\n\n\nFigures show the percent of simulation runs that have identified an item as misfitting. Items with more than 5% (crossing the lower horizontal line) are colored in light red. A dashed horizontal line indicates 90% detection rate. A number representing the detection rate is shown nearby the bar for the misfitting item. Columns are labelled with the number of iterations used by `RIgetfit()` to determine cutoff values, and rows are labelled with the sample size.\n\n#### Infit\n\n\n\n\n\n\n::: {#cell-fig-ifb0 .cell}\n\n```{.r .cell-code .hidden}\nifb %>% \n  group_by(targeting, samplesize, sims) %>% \n  filter(!infit_diff == \"no misfit\",\n         targeting == 0) %>% \n  count(item, .drop = F) %>% \n  mutate(Percent = n/200*100) %>% \n  \n  ggplot(aes(x = item, y = Percent)) +\n  geom_col(aes(fill = ifelse(Percent > 5, \"a\",\"b\"))) +\n  geom_hline(yintercept = 5) +\n  geom_text(data = . %>% filter(item == 9),\n            aes(label = Percent), \n            position = position_dodge(width = 0.9),\n            hjust = -0.3, vjust = 1) +\n  scale_y_continuous(limits = c(0,105), breaks = seq(0,100,25)) +\n  scale_x_continuous('Item', limits = c(1,20), breaks = seq(1,20,2), guide = guide_axis(n.dodge = 1)) +\n  guides(fill = \"none\") +\n  facet_grid(samplesize~sims) +\n  theme_rise() +\n  geom_hline(yintercept = 90, linetype = \"dashed\", linewidth = 0.3) +\n  labs(subtitle = \"Targeting 0 logits (item 9 misfit). 200 simulations per combination.\",\n       title = \"Conditional infit detection rate\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Removed 18 rows containing missing values or values outside the scale range\n(`geom_col()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-jats/fig-ifb0-1.png){#fig-ifb0}\n:::\n:::\n\n\n\n\n\n\n@fig-ifb0 shows the detection rate when the misfitting item is located at the sample mean. Detection rate is highest for the condition with 100 iterations with sample size 100 and 250, but it also shows higher levels of false positives when sample size increases to 500 or more.\n\n\n\n\n\n\n::: {#cell-fig-ifb1 .cell}\n\n```{.r .cell-code .hidden}\nifb %>% \n  group_by(targeting, samplesize, sims) %>% \n  filter(!infit_diff == \"no misfit\",\n         targeting == 1) %>% \n  count(item, .drop = F) %>% \n  mutate(Percent = n/200*100) %>% \n  \n  ggplot(aes(x = item, y = Percent)) +\n  geom_col(aes(fill = ifelse(Percent > 5, \"a\",\"b\"))) +\n  geom_hline(yintercept = 5) +\n  geom_text(data = . %>% filter(item == 18),\n            aes(label = Percent), \n            position = position_dodge(width = 0.9),\n            hjust = 1.2, vjust = 1) +\n  scale_y_continuous(limits = c(0,105), breaks = seq(0,100,25)) +\n  scale_x_continuous('Item', limits = c(1,20), breaks = seq(1,20,2), guide = guide_axis(n.dodge = 1)) +\n  guides(fill = \"none\") +\n  facet_grid(samplesize~sims) +\n  theme_rise() +\n  geom_hline(yintercept = 90, linetype = \"dashed\", linewidth = 0.3) +\n  labs(subtitle = \"Targeting -1 logits (item 18 misfit). 200 simulations per combination.\",\n       title = \"Conditional infit detection rate\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Removed 20 rows containing missing values or values outside the scale range\n(`geom_col()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-jats/fig-ifb1-1.png){#fig-ifb1}\n:::\n:::\n\n\n\n\n\n\nWhen the misfitting item is offset in targeting by -1 logits compared to the sample mean (see @fig-ifb1), the smallest sample size has less power to detect misfit compared to the on-target misfitting item. There are lower rates of false positives across all sample sizes and iterations.\n\n\n\n\n\n\n::: {#cell-fig-ifb2 .cell}\n\n```{.r .cell-code .hidden}\nifb %>% \n  group_by(targeting, samplesize, sims) %>% \n  filter(!infit_diff == \"no misfit\",\n         targeting == 2) %>% \n  count(item, .drop = F) %>% \n  mutate(Percent = n/200*100) %>% \n  \n  ggplot(aes(x = item, y = Percent)) +\n  geom_col(aes(fill = ifelse(Percent > 5, \"a\",\"b\"))) +\n  geom_hline(yintercept = 5) +\n  geom_text(data = . %>% filter(item == 13),\n            aes(label = Percent), \n            position = position_dodge(width = 0.9),\n            hjust = 1.2, vjust = 1) +\n  scale_y_continuous(limits = c(0,105), breaks = seq(0,100,25)) +\n  scale_x_continuous('Item', limits = c(1,20), breaks = seq(1,20,2), guide = guide_axis(n.dodge = 1)) +\n  guides(fill = \"none\") +\n  facet_grid(samplesize~sims) +\n  theme_rise() +\n  geom_hline(yintercept = 90, linetype = \"dashed\", linewidth = 0.3) +\n  labs(subtitle = \"Targeting -2 logits (item 13 misfit). 200 simulations per combination.\",\n       title = \"Conditional infit detection rate\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Removed 16 rows containing missing values or values outside the scale range\n(`geom_col()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-jats/fig-ifb2-1.png){#fig-ifb2}\n:::\n:::\n\n\n\n\n\n\nFinally, when the misfitting item is located at -2 logits compared to the sample mean (see @fig-ifb2), we see a stronger reduction in power for sample sizes 150 and 250. No false positives are identified.\n\n#### Outfit\n\n\n\n\n\n\n::: {#cell-fig-ifb0out .cell}\n\n```{.r .cell-code .hidden}\nifb %>% \n  group_by(targeting, samplesize, sims) %>% \n  filter(!outfit_diff == \"no misfit\",\n         targeting == 0) %>% \n  count(item, .drop = F) %>% \n  mutate(Percent = n/200*100) %>% \n  \n  ggplot(aes(x = item, y = Percent)) +\n  geom_col(aes(fill = ifelse(Percent > 5, \"a\",\"b\"))) +\n  geom_hline(yintercept = 5) +\n  geom_text(data = . %>% filter(item == 9),\n            aes(label = Percent), \n            position = position_dodge(width = 0.9),\n            hjust = -0.3, vjust = 1) +\n  scale_y_continuous(limits = c(0,105), breaks = seq(0,100,25)) +\n  scale_x_continuous('Item', limits = c(1,20), breaks = seq(1,20,2), guide = guide_axis(n.dodge = 1)) +\n  guides(fill = \"none\") +\n  facet_grid(samplesize~sims) +\n  theme_rise() +\n  geom_hline(yintercept = 90, linetype = \"dashed\", linewidth = 0.3) +\n  labs(subtitle = \"Targeting 0 logits (item 9 misfit). 200 simulations per combination.\",\n       title = \"Conditional outfit detection rate\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Removed 17 rows containing missing values or values outside the scale range\n(`geom_col()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-jats/fig-ifb0out-1.png){#fig-ifb0out}\n:::\n:::\n\n::: {#cell-fig-ifb1out .cell}\n\n```{.r .cell-code .hidden}\nifb %>% \n  group_by(targeting, samplesize, sims) %>% \n  filter(!outfit_diff == \"no misfit\",\n         targeting == 1) %>% \n  count(item, .drop = F) %>% \n  mutate(Percent = n/200*100) %>% \n  \n  ggplot(aes(x = item, y = Percent)) +\n  geom_col(aes(fill = ifelse(Percent > 5, \"a\",\"b\"))) +\n  geom_hline(yintercept = 5) +\n  geom_text(data = . %>% filter(item == 18),\n            aes(label = Percent), \n            position = position_dodge(width = 0.9),\n            hjust = 1.2, vjust = 1) +\n  scale_y_continuous(limits = c(0,105), breaks = seq(0,100,25)) +\n  scale_x_continuous('Item', limits = c(1,20), breaks = seq(1,20,2), guide = guide_axis(n.dodge = 1)) +\n  guides(fill = \"none\") +\n  facet_grid(samplesize~sims) +\n  theme_rise() +\n  geom_hline(yintercept = 90, linetype = \"dashed\", linewidth = 0.3) +\n  labs(subtitle = \"Targeting -1 logits (item 18 misfit). 200 simulations per combination.\",\n       title = \"Conditional outfit detection rate\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Removed 19 rows containing missing values or values outside the scale range\n(`geom_col()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-jats/fig-ifb1out-1.png){#fig-ifb1out}\n:::\n:::\n\n::: {#cell-fig-ifb2out .cell}\n\n```{.r .cell-code .hidden}\nifb %>% \n  group_by(targeting, samplesize, sims) %>% \n  filter(!outfit_diff == \"no misfit\",\n         targeting == 2) %>% \n  count(item, .drop = F) %>% \n  mutate(Percent = n/200*100) %>% \n  \n  ggplot(aes(x = item, y = Percent)) +\n  geom_col(aes(fill = ifelse(Percent > 5, \"a\",\"b\"))) +\n  geom_hline(yintercept = 5) +\n  geom_text(data = . %>% filter(item == 13),\n            aes(label = Percent), \n            position = position_dodge(width = 0.9),\n            hjust = -0.3, vjust = 1) +\n  scale_y_continuous(limits = c(0,105), breaks = seq(0,100,25)) +\n  scale_x_continuous('Item', limits = c(1,20), breaks = seq(1,20,2), guide = guide_axis(n.dodge = 1)) +\n  guides(fill = \"none\") +\n  facet_grid(samplesize~sims) +\n  theme_rise() +\n  geom_hline(yintercept = 90, linetype = \"dashed\", linewidth = 0.3) +\n  labs(subtitle = \"Targeting -2 logits (item 13 misfit). 200 simulations per combination.\",\n       title = \"Conditional outfit detection rate\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Removed 14 rows containing missing values or values outside the scale range\n(`geom_col()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-jats/fig-ifb2out-1.png){#fig-ifb2out}\n:::\n:::\n\n\n\n\n\n\nAs shown in @fig-ifb0out, @fig-ifb1out, and @fig-ifb2out, outfit is performing much worse than infit across the board.\n\n#### Comments\n\nBased on these simulation, it seems reasonable to recommend the use of infit in determining item fit over outfit. The performance of outfit calls to question whether it is useful at all.\n\nRegarding infit, it looks like 100 iterations are to recommend to determine cutoff values when the sample size is 250 or lower, while 200 or 400 iterations reduce the risk for false positives at sample sizes of 500 or larger. False positives are found at sample sizes 500 and 1000 only. The risk for false positives is notably higher when the misfitting item is located at the sample mean compared to when the misfitting item is off-target by -1 logits or more.\n\nThese findings make a good argument for removing one item at a time when the analysis indicates misfit, starting with the most misfitting item. This is especially relevant for sample sizes at 500 or above and when misfitting items are located close to the sample mean.\n\n## Study 2\n\nItem-restscore using the same datasets and adding the dataset with all three items misfitting.\n\n## Study 3 \n\nItem-restscore bootstrapped to better handle big samples, but also perhaps for smaller samples?\n\n## Discussion\n\n## Conclusion\n\n## References {.unnumbered}\n\n:::{#refs}\n\n:::",
    "supporting": [
      "index_files/figure-jats"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}