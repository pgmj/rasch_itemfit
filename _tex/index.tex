% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Detecting item misfit in Rasch models},
  pdfauthor={Magnus Johansson},
  pdfkeywords={Rasch, Psychometrics, Item fit, Simulation},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Detecting item misfit in Rasch models}
\author{Magnus Johansson}
\date{2025-01-04}

\begin{document}
\maketitle
\begin{abstract}
Psychometrics in general have long relied on rule-of-thumb critical
values for various goodness of fit metrics. With more powerful personal
computers it is both feasible and desirable to use simulation methods to
determine appropriate critical cutoff values. This paper illustrates and
evaluates the use of an R package for Rasch psychometrics that has
implemented functions to simplify the process of determining simulation
based cutoff values. Through a series of simulation studies a comparison
is made between information weighted conditional item fit (``infit'')
and item-restscore correlations using Goodman and Kruskal's \(\gamma\).
Results indicate the limitations of small samples (n \textless{} 500) in
correctly detecting item misfit, especially when several items are
misfit. Item outfit shows very low performance and should not be used.
Conditional infit with simulation based cutoffs performs slightly better
than item-restscore with samples below n = 500. Both methods have
strongly increased rates of false positives with large samples (n
\textgreater= 1000). Large samples should use non-parametric bootstrap
of subsamples with item-restscore to avoid type-1 errors. Finally, the
importance of iterative analyses is emphasized since a situation where
several items show underfit will induce seemingly overfit items.
Underfit item should be removed one at a time, and a re-analysis
conducted for each step to avoid erroneously removing items.
\end{abstract}


\section{Introduction}\label{introduction}

This paper presents a series of simulations conducted to evaluate
methods to detect of item misfit in Rasch models. First, conditional
item infit and outfit will be under scrutiny. Second, item infit will be
compared to item-restscore (Kreiner 2011; Mueller and Santiago 2022).
Third, a bootstrap method for item-restscore will be presented and
tested.

The assessment of item fit under the Rasch model has for decades been
conducted using various rule-of-thumb critical values. Müller (2020)
showed how the range of critical values for conditional item infit
varies with sample size. The expected average item conditional infit
range was described by Müller as fairly well captured by Smith's
rule-of-thumb formula 1±2/√n (Smith, Schumacker, and Bush 1998).
However, the average range does not apply for all items, since item
location relative to sample location also affects model expected item
fit. This means that some items within a set of items varying in
location are likely to have item fit values outside Smith's average
value range while still fitting the Rasch model.

It is here proposed that by using parametric bootstrapping one can
establish item fit critical cutoff values that are sample and item
specific. This procedure uses the estimated item and person locations
based on the available data and simulates new response data that fit the
Rasch model, to determine the range of plausible item fit values for
each item. The R package \texttt{easyRasch} (Johansson 2024) includes a
function to determine item infit and outfit cutoff values using this
method and will be tested in the simulations in this paper.

It is important to note that the conditional item fit described by
Müller (2020) and implemented in the \texttt{iarm} R package (Mueller
and Santiago 2022) should not be confused with the unconditional item
fit implemented in software such as Winsteps and RUMM2030, as well as
all R packages except \texttt{iarm}. Unconditional item fit can result
in unreliable item fit in sample sizes as small as 250 with increasing
likelihood of problems as sample size increases. Readers are strongly
recommended to read Müller's paper to fully understand the issues with
unconditional item fit.

\section{Methods}\label{methods}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

A fully reproducible manuscript with R code and data is available on
GitHub: \url{https://github.com/pgmj/rasch_itemfit}

The simulation of response data used three steps: First, a vector of
theta values (person scores on the latent variable's logit scale) were
generated using \texttt{rnorm(mean\ =\ 0,\ sd\ =\ 1.5)}. Second, a set
of item locations ranging from -2 to 2 logits were generated for
dichotomous items, using
\texttt{runif(n\ =\ 20,\ min\ =\ -2,\ max\ =\ 2)}. Third, the theta
values were used to simulate item responses for participants, using
\texttt{sim.xdim()} from the \texttt{eRm} package (Mair and Hatzinger
2007), which allows simulation of multidimensional response data.
Multiple datasets with 10 000 respondents each were generated using the
same item and person parameters, varying the targeting of the misfitting
item(s) and number of the misfitting item(s). More details are described
under the separate studies. The parametric bootstrapping procedure was
implemented using random samples from the simulated datasets. Sample
size variations tested are described under each study.

The general procedure for the parametric bootstrapping is as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimation of item locations based on simulated item response data,
  using conditional maximum likelihood (CML, Mair and Hatzinger 2007).
\item
  Estimation of sample theta values using weighted maximum likelihood
  (Warm 1989).
\item
  Simulation of new response data which fit the Rasch model, using the
  estimated item locations and theta values.
\item
  Estimation of the dichotomous Rasch model for the new response data
  using CML.
\item
  Based on step 4, calculation of conditional item infit and outfit
  (Müller 2020; Mueller and Santiago 2022) and/or item-restscore metrics
  (Kreiner 2011; Mueller and Santiago 2022).
\end{enumerate}

Steps three and four were iterated over, using resampling with
replacement from the estimated theta values as a basis for simulating
the response data in step three.

Summary statistics were created with focus on the percentage of correct
detection of misfit and false positives.

A complete list of software used for the analyses is listed in
\#sec-addmat.

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\section{Study 1: Item infit and
outfit}\label{study-1-item-infit-and-outfit}

Item mean square standardized residuals are either unweighted, which is
referred to as ``outfit'', or information weighted, which we call
``infit'' (Ostini and Nering 2006, 86--87). For details on conditional
item fit we refer to the previously mentioned paper by Müller (2020).
Conditional item infit and outfit are expected to be near 1, with higher
values indicating an item to be underfitting the Rasch model (often due
to multidimensionality issues) and lower values indicating overfit.

The function \texttt{RIgetfit()} from the \texttt{easyRasch} R package
is tested here. It's source code can be accessed on GitHub, see
\#sec-addmat. The function offers the user a choice of the number of
bootstrap iterations to use to determine the critical cutoff values for
each item's infit and outfit. Our main interest in this study is
two-fold. We want to test variations in the number of iterations used in
\texttt{RIgetfit()} and evaluate how well the critical values based on
the parametric bootstrapping procedure detects misfitting items.
Additionally, a comparison between infit and outfit statistics in terms
of detection rate and false positive rate will be conducted.

20 dichotomous items are used, with one item misfitting. Item locations
are the same throughout all studies unless otherwise noted. The location
of the misfitting item relative the to the sample theta mean was
selected to be approximately 0, -1, and -2 logits. Three separate
datasets were generated with these variations, each with 10 000
simulated respondents. One dataset with all three misfitting items was
also generated, using the same sample size.

Then the \texttt{RIitemfit()} function is used to summarize the
bootstrap results and also calculates the infit and outfit for each item
in the observed data and highlights items with infit/outfit values
outside of the cutoff values. \texttt{RIitemfit()} has a default (user
modifiable) setting to slightly truncate the distribution of values
using \texttt{stats::quantile()} at 0.001 and 0.999 to remove extreme
values. An example is demonstrated in Table~\ref{tbl-itemfit1}, using a
subset of the items used in the simulations. Figure~\ref{fig-itemfit1}
provides a visualization of the distribution of bootstrapped infit and
outfit values, together with the infit/outfit values from the observed
data illustrated using an orange diamond shape. Note the variation
between items in plausible values of infit and outfit based on the
bootstrap, and that Smith's rule-of-thumb regarding infit (1±2/√n) would
be 0.9-1.1 for a sample size of 400.

This study was rather computationally demanding since each simulation
run entailed 100-400 underlying bootstrap iterations. The sample sizes
used were 150, 250, 500, and 1000. The number of iterations to determine
cutoff values were 100, 200, and 400. Sample size and iteration
conditions were fully crossed with each other and the three different
targeting variations of the one misfitting item, resulting in 4\emph{3}3
= 36 conditions. Each combination used 200 simulation runs. The
simulations took about 12 hours to run on a Macbook Pro Max M1 using 9
CPU cores.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0549}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0989}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1868}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1099}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1978}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1209}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1319}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0989}}@{}}

\caption{\label{tbl-itemfit1}Conditional item fit with simulation based
cutoff values}

\tabularnewline

\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Item
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
InfitMSQ
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Infit thresholds
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
OutfitMSQ
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Outfit thresholds
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Infit diff
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Outfit diff
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Location
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
V1 & 1.017 & {[}0.874, 1.138{]} & 1.061 & {[}0.631, 1.605{]} & no misfit
& no misfit & -1.37 \\
V11 & 1.000 & {[}0.808, 1.184{]} & 1.032 & {[}0.666, 1.277{]} & no
misfit & no misfit & -0.66 \\
V3 & 1.022 & {[}0.918, 1.119{]} & 1.050 & {[}0.668, 1.554{]} & no misfit
& no misfit & 0.46 \\
V12 & 0.966 & {[}0.841, 1.189{]} & 0.793 & {[}0.803, 1.28{]} & no misfit
& 0.01 & 1.58 \\

\end{longtable}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\phantomsection\label{cell-fig-itemfit1}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-itemfit1-1.pdf}}

}

\caption{\label{fig-itemfit1}Distribution of simulation based item fit
and estimated item fit from observed data}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\subsection{Results}\label{results}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

Figures show the percent of simulation runs that have identified an item
as misfitting. Items with more than 5\% are colored in light red. A
number representing the detection rate is shown adjacent to the bar
representing the misfitting item. The figure grid columns are labelled
with the number of iterations used by \texttt{RIgetfit()} to determine
cutoff values, and grid rows are labelled with the sample size.

\subsubsection{Infit}\label{infit}

\phantomsection\label{cell-fig-ifb0}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-ifb0-1.pdf}}

}

\caption{\label{fig-ifb0}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

Figure~\ref{fig-ifb0} shows the detection rate when the misfitting item
is located at the sample mean. Detection rate is highest for the
condition with 100 iterations with sample size 100 and 250, but it also
shows higher levels of false positives when sample size increases to 500
or more.

\phantomsection\label{cell-fig-ifb1}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-ifb1-1.pdf}}

}

\caption{\label{fig-ifb1}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

When the misfitting item is offset in targeting by -1 logits compared to
the sample mean (see Figure~\ref{fig-ifb1}), the smallest sample size
has less power to detect misfit compared to the on-target misfitting
item. There are lower rates of false positives across all sample sizes
and iterations.

\phantomsection\label{cell-fig-ifb2}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-ifb2-1.pdf}}

}

\caption{\label{fig-ifb2}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

Finally, when the misfitting item is located at -2 logits compared to
the sample mean (see Figure~\ref{fig-ifb2}), we see a stronger reduction
in power for sample sizes 150 and 250. No false positives are
identified.

\subsubsection{Outfit}\label{outfit}

\phantomsection\label{cell-fig-ifb0out}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-ifb0out-1.pdf}}

}

\caption{\label{fig-ifb0out}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\phantomsection\label{cell-fig-ifb1out}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-ifb1out-1.pdf}}

}

\caption{\label{fig-ifb1out}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\phantomsection\label{cell-fig-ifb2out}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-ifb2out-1.pdf}}

}

\caption{\label{fig-ifb2out}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

As shown in Figure~\ref{fig-ifb0out}, Figure~\ref{fig-ifb1out}, and
Figure~\ref{fig-ifb2out}, outfit is performing much worse than infit
across the board.

\subsubsection{Comments}\label{comments}

Based on these simulation, it seems reasonable to recommend the use of
infit in determining item fit over outfit. The performance of outfit
calls to question whether it is useful at all.

Regarding infit and the use of parametric bootstrapping with
\texttt{RIgetfit()}, it looks like 100 iterations are to recommend to
determine cutoff values when the sample size is 250 or lower, while 200
or 400 iterations reduce the risk for false positives at sample sizes of
500 or larger. False positives are found at sample sizes 500 and 1000
only. The risk for false positives is notably higher when the misfitting
item is located at the sample mean compared to when the misfitting item
is off-target by -1 logits or more.

\section{Study 2: Item-restscore}\label{study-2-item-restscore}

Item-restscore is a metric that compares an expected correlation with
the observed correlation, using Goodman and Kruskal's \(\gamma\)
(Goodman and Kruskal 1954; Kreiner 2011). Lower observed values than
expected indicates than an item is underfit to the Rasch model, while
higher values indicate overfit. The item-restscore function used in this
simulation is from the \texttt{iarm} package (Mueller and Santiago 2022)
and outputs Benjamini-Hochberg corrected \emph{p}-values (Benjamini and
Hochberg 1995), which are used to determine whether the differences
between the observed and expected values are statistically significant
(using \emph{p} \textless{} .05 as critical value) for each item.

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\subsection{Results}\label{results-1}

\phantomsection\label{cell-fig-itemrestscore1}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-itemrestscore1-1.pdf}}

}

\caption{\label{fig-itemrestscore1}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

This simulation includes an additional condition with 100 respondents,
which results in significantly lower detection rates than with 150
respondents. Compared to infit at 250 respondents, item-restscore has
detection rates of 95.2\%, 90.9\%, and 62.4\% for targeting 0, -1, and
-2, while infit has 96.5\%, 96.5\%, and 71\%. For sample size 500 and
1000, performance is similar, including the increased tendency for false
positives at n = 1000.

Similarly to infit, item-restscore has decreased detection rate for
off-target misfitting items. The false positive rate is lower for
item-restscore than infit for sample sizes below 1000.

\section{Study 3: Comparing infit and
item-restscore}\label{study-3-comparing-infit-and-item-restscore}

We will now compare the performance of infit and item-restscore when all
three items are misfitting at the same time. This simulation will also
include a condition with 2000 respondents, to examine if the false
positive rate increases with more respondents. For infit, we will only
use 200 iterations with \texttt{RIgetfit()} since that condition seemed
to strike a balance between detection rate and false positives.

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\subsubsection{Results}\label{results-2}

\phantomsection\label{cell-fig-ifb3}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-ifb3-1.pdf}}

}

\caption{\label{fig-ifb3}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\phantomsection\label{cell-fig-ifb3out}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-ifb3out-1.pdf}}

}

\caption{\label{fig-ifb3out}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

Looking at the performance of infit with three misfitting items
(Figure~\ref{fig-ifb3}), we can see that the detection rate is markedly
worse for item 13 (targeting -1 logits) in sample sizes 500 and below,
compared to when single items were misfitting. The false positive rate
has increased for sample size of 1000 and we can see it escalate when n
= 2000. Outfit (Figure~\ref{fig-ifb3out}) again performs worse than
infit.

\phantomsection\label{cell-fig-itemrestscore2}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-itemrestscore2-1.pdf}}

}

\caption{\label{fig-itemrestscore2}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\begin{longtable}[]{@{}rlr@{}}

\caption{\label{tbl-overunder}}

\tabularnewline

\toprule\noalign{}
Item & Type of misfit & n \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & overfit & 299 \\
2 & overfit & 520 \\
3 & overfit & 224 \\
4 & overfit & 181 \\
5 & overfit & 298 \\
6 & overfit & 475 \\
7 & overfit & 313 \\
8 & overfit & 382 \\
9 & underfit & 2132 \\
10 & overfit & 365 \\
11 & overfit & 326 \\
12 & overfit & 149 \\
12 & underfit & 2 \\
13 & underfit & 1595 \\
14 & overfit & 182 \\
15 & overfit & 313 \\
16 & overfit & 278 \\
17 & overfit & 129 \\
18 & underfit & 1974 \\
19 & overfit & 31 \\
20 & overfit & 387 \\

\end{longtable}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

Item-restscore has higher detection rate than infit (see
Figure~\ref{fig-itemrestscore2}), but also higher levels of false
positives. Reviewing the type of misfit identified by item-restscore
(see Table~\ref{tbl-overunder}), the false positives are all overfitting
the Rasch model, except for two instances indicating underfit for item
12. Items 9, 13, and 18, that were simulated to be misfitting due to
loading on a separate dimension, are as expected showing underfit to the
Rasch model.

\section{Study 4: Bootstrapped
item-restscore}\label{study-4-bootstrapped-item-restscore}

For our final set of simulations, we will use a non-parametric bootstrap
procedure with item-restscore. The difference from the parametric
bootstrap is that the non-parametric bootstrap samples with replacement
directly from the observed response data. First, based on the above
problematic sample size of 2000 when three items are misfitting, we will
use the bootstrap function to sample with replacement using n = 800 and
250 bootstrap samples. The function \texttt{RIbootRestscore()} from the
\texttt{easyRasch} package will be used.

\begin{longtable}[]{@{}llr@{}}

\caption{\label{tbl-bootir}Example output from
\texttt{RIbootRestscore()}}

\tabularnewline

\toprule\noalign{}
Item & Item-restscore result & Percent of iterations \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
V18 & underfit & 100.0 \\
V9 & underfit & 100.0 \\
V13 & underfit & 92.8 \\
V2 & overfit & 73.6 \\
V10 & overfit & 34.0 \\
V6 & overfit & 31.2 \\
V7 & overfit & 28.4 \\
V8 & overfit & 22.4 \\
V15 & overfit & 20.0 \\
V5 & overfit & 19.6 \\
V4 & overfit & 12.0 \\
V16 & overfit & 11.6 \\
V20 & overfit & 8.8 \\
V11 & overfit & 8.0 \\
V1 & overfit & 6.8 \\
V17 & overfit & 4.8 \\
V14 & overfit & 3.2 \\
V19 & overfit & 1.2 \\
V3 & overfit & 1.2 \\
V12 & overfit & 0.4 \\
V12 & underfit & 0.4 \\
V14 & underfit & 0.4 \\

\end{longtable}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\texttt{RIbootRestscore()} is demonstrated using a single sample in
Table~\ref{tbl-bootir}, where the table is sorted on Percent of
iterations. The runtime was around 10-12 seconds using 8 CPU cores on a
Macbook Pro M1 Max. In our simulation, we will repeat this procedure 500
times and report the average and standard deviation for the percent
indicating misfit for each item.

Second, we will also apply the bootstrapped item-restscore method to
sample sizes 150 and 250, using the complete sample for the same
bootstrap procedure to see if this produces more useful information than
previously tested strategies for identifying misfitting items.

\subsection{Results}\label{results-3}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\phantomsection\label{cell-fig-irb0all}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-irb0all-1.pdf}}

}

\caption{\label{fig-irb0all}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\begin{table}

\caption{\label{tbl-irb0mis}Summary statistics for item-restscore
bootstrap simulation}

\begin{minipage}{\linewidth}

\subcaption{\label{tbl-irb0mis-1}Misfitting items}

\centering{

\begin{tabular}{lrrrrrr}
\toprule
Item & Median & MAD & Mean & SD & p05 & p01\\
\midrule
V9 & 100.0 & 0.0 & 100.0 & 0.1 & 100.0 & 99.6\\
V18 & 100.0 & 0.0 & 99.8 & 0.9 & 99.2 & 98.0\\
V13 & 95.6 & 4.7 & 93.0 & 8.0 & 76.4 & 64.0\\
\bottomrule
\end{tabular}

}

\end{minipage}%
\newline
\begin{minipage}{\linewidth}

\subcaption{\label{tbl-irb0mis-2}False positives}

\centering{

\begin{tabular}{lrrrrrr}
\toprule
Item & Median & MAD & Mean & SD & p95 & p99\\
\midrule
V2 & 20.0 & 15.4 & 24.3 & 16.7 & 58.8 & 70.0\\
V8 & 14.4 & 12.5 & 19.7 & 15.6 & 51.6 & 65.6\\
V6 & 18.4 & 14.2 & 21.3 & 14.9 & 52.8 & 64.0\\
V11 & 14.0 & 11.9 & 17.6 & 13.9 & 47.7 & 62.4\\
V15 & 13.2 & 10.1 & 16.6 & 13.4 & 45.2 & 61.7\\
V1 & 12.0 & 10.1 & 15.5 & 12.8 & 41.3 & 59.7\\
V10 & 13.2 & 11.3 & 16.4 & 13.0 & 42.4 & 58.5\\
V16 & 11.4 & 10.4 & 15.2 & 13.0 & 42.0 & 58.4\\
V20 & 16.4 & 13.6 & 19.5 & 13.9 & 45.2 & 57.2\\
V5 & 12.0 & 10.1 & 15.7 & 12.6 & 44.4 & 52.8\\
V7 & 13.2 & 11.9 & 16.7 & 12.6 & 41.6 & 51.7\\
V3 & 10.8 & 9.5 & 13.6 & 11.2 & 36.1 & 49.3\\
V14 & 7.2 & 6.5 & 10.4 & 10.1 & 30.7 & 47.0\\
V12 & 7.6 & 7.7 & 10.4 & 9.5 & 29.7 & 41.4\\
V4 & 7.2 & 6.5 & 10.2 & 9.5 & 29.3 & 40.1\\
V17 & 6.4 & 6.5 & 8.4 & 8.0 & 24.4 & 32.6\\
V19 & 2.4 & 2.4 & 3.9 & 4.6 & 13.6 & 19.5\\
\bottomrule
\end{tabular}

}

\end{minipage}%

\end{table}%

Figure~\ref{fig-irb0all} shows that there is variation in false positive
rate, but it is nearly always indicating overfit, while the misfitting
items are only indicated as underfit. The summary statistics in
Table~\ref{tbl-irb0mis} show that there can be quite a bit of variation
for false positives, but the clear majority of results are below 50\%. 3
items have 95th percentile values above 50, with the highest at 58.8.

\subsection{Small sample (n = 150)}\label{small-sample-n-150}

We will use 200 simulations to check the performance of the bootstrapped
item-restscore function for sample size 150. As an additional
experimental condition, we will use both 250 and 500 bootstraps for
item-restscore in each simulation.

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\phantomsection\label{cell-fig-irboot150}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-irboot150-1.pdf}}

}

\caption{\label{fig-irboot150}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

The bootstrapping does not improve on the single instance of
item-restscore for the n = 150 condition (see
Figure~\ref{fig-irboot150}). When comparing to the previous results in
Figure~\ref{fig-itemrestscore2}, where the detection rate for the same
sample size were at 49.2\%, 14.6\%, and 34.6\% (for items 9, 13, and 18
respectively), the corresponding median values from the bootstrapped
item-restscore with 250 iterations were 51.6\%, 12.4\%, and 37.2\%.
Using 500 bootstrap iterations did not result in relevant improvements
over 250 iterations (see Table~\ref{tbl-irb150mis}).

\begin{table}

\caption{\label{tbl-irb150mis}Summary statistics for item-restscore
bootstrap simulation (n = 150)}

\begin{minipage}{\linewidth}

\subcaption{\label{tbl-irb150mis-1}250 bootstrap iterations}

\centering{

\begin{tabular}{lrrrrrr}
\toprule
Item & Median & MAD & Mean & SD & p05 & p01\\
\midrule
V13 & 12.4 & 17.8 & 22.5 & 24.7 & 0.4 & 0.4\\
V18 & 37.2 & 36.2 & 40.4 & 28.4 & 0.9 & 0.4\\
V9 & 51.6 & 38.0 & 50.4 & 29.8 & 2.9 & 0.4\\
\bottomrule
\end{tabular}

}

\end{minipage}%
\newline
\begin{minipage}{\linewidth}

\subcaption{\label{tbl-irb150mis-2}500 bootstrap iterations}

\centering{

\begin{tabular}{lrrrrrr}
\toprule
Item & Median & MAD & Mean & SD & p05 & p01\\
\midrule
V13 & 12.7 & 17.9 & 21.9 & 24.3 & 0.2 & 0.2\\
V18 & 35.6 & 38.3 & 38.7 & 28.8 & 0.3 & 0.2\\
V9 & 53.0 & 39.1 & 50.3 & 29.9 & 3.6 & 0.2\\
\bottomrule
\end{tabular}

}

\end{minipage}%

\end{table}%

\section{Study 5: Varying number of
items}\label{study-5-varying-number-of-items}

When doing simulation studies there is always a balance to strike
between trying to evaluate many scenarios and not having too high
complexity. We have been keeping several things constant, such as item
locations and number of items, which makes interpretation easier but may
limit the applicability of the results. For our final simulation, we
will vary the number of items and the number of misfitting items. First,
40 dichotomous items will be used, adding 20 new item locations to the
previously used set, with the same three items misfitting (items 9, 13,
and 18). Second, items 1-10 out of the initial 20 items will be used,
which means only item 9 will be misfit. We'll again be using sample
sizes of 150, 250, 500, and 1000.

Item-restscore and item infit will be compared. The latter will use 100
bootstrap iterations to determine critical values for sample sizes 150
and 250, and 200 bootstrap iterations for n \textgreater= 500.

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\subsection{Results 40 items}\label{results-40-items}

\phantomsection\label{cell-fig-ifb40}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-ifb40-1.pdf}}

}

\caption{\label{fig-ifb40}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

\phantomsection\label{cell-fig-itemrestscore40}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-itemrestscore40-1.pdf}}

}

\caption{\label{fig-itemrestscore40}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

Infit performs better when sample size is 150 or 250 (see
Figure~\ref{fig-ifb40}), while performance is slightly better for
item-restscore for n \textgreater= 500 in terms of lower rates of false
positives (see Figure~\ref{fig-itemrestscore40}).

\subsection{Results 10 items}\label{results-10-items}

\phantomsection\label{cell-fig-itemrestscore10}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-itemrestscore10-1.pdf}}

}

\caption{\label{fig-itemrestscore10}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

Compared to when we had 20 items, \ldots{} create a summary table! And
run more simulations tonight.

\section{Discussion}\label{discussion}

\subsection{Limitations}\label{limitations}

Number of items could be varied more. However, the results from Müller
(2020), which use 10, 15, and 20 items, indicates small differences in
critical value ranges. But this might not have implications for
detection rate of misfitting items (we need the 40 items simulation and
maybe 10 also?). Partial credit model for polytomous data would have
been nice to also test. Although results regarding detection rate should
generalize from RM to PCM, maybe the sample size in relation to number
of items does not easily translate from the dichotomous case?

\section{Conclusion}\label{conclusion}

These findings make a good argument for removing one item at a time when
the analysis indicates misfitting items, starting with the most
underfitting item. This is especially relevant for \emph{n}
\textgreater= 500 and when misfitting items are located close to the
sample mean.

\phantomsection\label{cell-fig-loadloc}
\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{index_files/figure-pdf/fig-loadloc-1.pdf}}

}

\caption{\label{fig-loadloc}}

\end{figure}%

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}

Assessing item fit and dimensionality should be done using multiple
methods. Item fit and item-restscore should be used in parallel, while
also examining residual patterns by reviewing standardized factor
loadings on the first residual contrast (see Figure~\ref{fig-loadloc}
for an example) as well as Yen's Q3 residual correlations.

While the simulations in this paper have used dichotomous data, all
functions evaluated in this paper also work with polytomous data using
the Rasch Partial Credit Model.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-benjamini_controlling_1995}
Benjamini, Yoav, and Yosef Hochberg. 1995. {``Controlling the {False}
{Discovery} {Rate}: {A} {Practical} and {Powerful} {Approach} to
{Multiple} {Testing}.''} \emph{Journal of the Royal Statistical Society:
Series B (Methodological)} 57 (1): 289--300.
\url{https://doi.org/10.1111/j.2517-6161.1995.tb02031.x}.

\bibitem[\citeproctext]{ref-goodman_measures_1954}
Goodman, Leo A., and William H. Kruskal. 1954. {``Measures of
{Association} for {Cross} {Classifications}.''} \emph{Journal of the
American Statistical Association} 49 (268): 732--64.
\url{https://doi.org/10.2307/2281536}.

\bibitem[\citeproctext]{ref-easyrasch}
Johansson, Magnus. 2024. \emph{easyRasch: Psychometric Analysis in r
with Rasch Measurement Theory}. \url{https://github.com/pgmj/easyRasch}.

\bibitem[\citeproctext]{ref-kreiner_note_2011}
Kreiner, Svend. 2011. {``A {Note} on {Item}--{Restscore} {Association}
in {Rasch} {Models}.''} \emph{Applied Psychological Measurement} 35 (7):
557--61. \url{https://doi.org/10.1177/0146621611410227}.

\bibitem[\citeproctext]{ref-mair_extended_2007}
Mair, Patrick, and Reinhold Hatzinger. 2007. {``Extended {Rasch}
{Modeling}: {The} {eRm} {Package} for the {Application} of {IRT}
{Models} in {R}.''} \emph{Journal of Statistical Software} 20 (1):
1--20. \url{https://doi.org/10.18637/jss.v020.i09}.

\bibitem[\citeproctext]{ref-mueller_iarm_2022}
Mueller, Marianne, and Pedro Henrique Ribeiro Santiago. 2022. {``Iarm:
{Item} {Analysis} in {Rasch} {Models}.''}
\url{https://cran.r-project.org/web/packages/iarm/index.html}.

\bibitem[\citeproctext]{ref-muller_item_2020}
Müller, Marianne. 2020. {``Item Fit Statistics for {Rasch} Analysis: Can
We Trust Them?''} \emph{Journal of Statistical Distributions and
Applications} 7 (1): 5.
\url{https://doi.org/10.1186/s40488-020-00108-7}.

\bibitem[\citeproctext]{ref-ostini_polytomous_2006}
Ostini, Remo, and Michael Nering. 2006. \emph{Polytomous {Item}
{Response} {Theory} {Models}}. SAGE Publications, Inc.
\url{https://doi.org/10.4135/9781412985413}.

\bibitem[\citeproctext]{ref-smith_using_1998}
Smith, R. M., R. E. Schumacker, and M. J. Bush. 1998.
{``\href{https://www.ncbi.nlm.nih.gov/pubmed/9661732}{Using Item Mean
Squares to Evaluate Fit to the {Rasch} Model}.''} \emph{Journal of
Outcome Measurement} 2 (1): 66--78.

\bibitem[\citeproctext]{ref-warm_weighted_1989}
Warm, Thomas A. 1989. {``Weighted Likelihood Estimation of Ability in
Item Response Theory.''} \emph{Psychometrika} 54 (3): 427--50.
\url{https://doi.org/10.1007/BF02294627}.

\end{CSLReferences}

\section{Additional materials}\label{sec-addmat}

\begin{itemize}
\tightlist
\item
  GitHub link for \texttt{easyRasch} source code:
  \url{https://github.com/pgmj/easyRasch/}

  \begin{itemize}
  \tightlist
  \item
    Most functions are defined in this file:
    \url{https://github.com/pgmj/easyRasch/blob/main/R/easyRasch.R}
  \end{itemize}
\end{itemize}

\subsection{Session info}\label{session-info}

This documents the specific R packages and versions used in this study.

\begin{verbatim}
R version 4.4.2 (2024-10-31)
Platform: aarch64-apple-darwin20
Running under: macOS Sequoia 15.2

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0

locale:
[1] sv_SE.UTF-8/sv_SE.UTF-8/sv_SE.UTF-8/C/sv_SE.UTF-8/sv_SE.UTF-8

time zone: Europe/Stockholm
tzcode source: internal

attached base packages:
 [1] parallel  grid      stats4    stats     graphics  grDevices utils    
 [8] datasets  methods   base     

other attached packages:
 [1] showtext_0.9-7    showtextdb_3.0    sysfonts_0.8.9    arrow_16.1.0     
 [5] easyRasch_0.3.3   doParallel_1.0.17 iterators_1.0.14  furrr_0.3.1      
 [9] future_1.34.0     foreach_1.5.2     janitor_2.2.0     hexbin_1.28.4    
[13] catR_3.17         glue_1.8.0        ggrepel_0.9.6     patchwork_1.3.0  
[17] reshape_0.8.9     matrixStats_1.4.1 psychotree_0.16-1 psychotools_0.7-4
[21] partykit_1.2-22   mvtnorm_1.3-1     libcoin_1.0-10    psych_2.4.6.26   
[25] mirt_1.43         lattice_0.22-6    kableExtra_1.4.0  formattable_0.2.1
[29] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      
[33] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     
[37] tidyverse_2.0.0   ggdist_3.3.2      iarm_0.4.3        ggplot2_3.5.1    
[41] eRm_1.0-6        

loaded via a namespace (and not attached):
  [1] splines_4.4.2        R.oo_1.26.0          cellranger_1.1.0    
  [4] rpart_4.1.23         lifecycle_1.0.4      rprojroot_2.0.4     
  [7] globals_0.16.3       vroom_1.6.5          MASS_7.3-61         
 [10] backports_1.5.0      magrittr_2.0.3       vcd_1.4-12          
 [13] Hmisc_5.2-0          rmarkdown_2.28       yaml_2.3.10         
 [16] sessioninfo_1.2.2    pbapply_1.7-2        RColorBrewer_1.1-3  
 [19] audio_0.1-11         quadprog_1.5-8       R.utils_2.12.3      
 [22] nnet_7.3-19          listenv_0.9.1        testthat_3.2.1.1    
 [25] RPushbullet_0.3.4    vegan_2.6-8          parallelly_1.38.0   
 [28] svglite_2.1.3        permute_0.9-7        codetools_0.2-20    
 [31] xml2_1.3.6           tidyselect_1.2.1     farver_2.1.2        
 [34] base64enc_0.1-3      jsonlite_1.8.9       progressr_0.14.0    
 [37] Formula_1.2-5        survival_3.7-0       systemfonts_1.1.0   
 [40] tools_4.4.2          gnm_1.1-5            snow_0.4-4          
 [43] Rcpp_1.0.13-1        mnormt_2.1.1         gridExtra_2.3       
 [46] xfun_0.46            here_1.0.1           mgcv_1.9-1          
 [49] distributional_0.4.0 ca_0.71.1            withr_3.0.2         
 [52] beepr_2.0            fastmap_1.2.0        fansi_1.0.6         
 [55] digest_0.6.37        timechange_0.3.0     R6_2.5.1            
 [58] colorspace_2.1-1     R.methodsS3_1.8.2    inum_1.0-5          
 [61] utf8_1.2.4           generics_0.1.3       data.table_1.16.0   
 [64] SimDesign_2.17.1     htmlwidgets_1.6.4    pkgconfig_2.0.3     
 [67] gtable_0.3.5         lmtest_0.9-40        brio_1.1.5          
 [70] htmltools_0.5.8.1    scales_1.3.0         snakecase_0.11.1    
 [73] knitr_1.48           rstudioapi_0.17.1    tzdb_0.4.0          
 [76] checkmate_2.3.2      nlme_3.1-166         curl_6.0.1          
 [79] zoo_1.8-12           relimp_1.0-5         vcdExtra_0.8-5      
 [82] foreign_0.8-87       pillar_1.9.0         vctrs_0.6.5         
 [85] Deriv_4.1.3          cluster_2.1.6        dcurver_0.9.2       
 [88] archive_1.1.8        GPArotation_2024.3-1 htmlTable_2.4.3     
 [91] evaluate_1.0.1       cli_3.6.3            compiler_4.4.2      
 [94] rlang_1.1.4          crayon_1.5.3         future.apply_1.11.2 
 [97] labeling_0.4.3       plyr_1.8.9           stringi_1.8.4       
[100] viridisLite_0.4.2    assertthat_0.2.1     munsell_0.5.1       
[103] Matrix_1.7-1         qvcalc_1.0.3         hms_1.1.3           
[106] bit64_4.0.5          bit_4.0.5            readxl_1.4.3        
\end{verbatim}

\textsubscript{Source:
\href{https://pgmj.github.io/rasch_itemfit/index.qmd.html}{Article
Notebook}}




\end{document}
